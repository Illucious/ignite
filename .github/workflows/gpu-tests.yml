name: Run unit tests on GPUs
on:
  push:
    paths:
      - "ignite/**"
      - "tests/ignite/**"
      - "tests/run_gpu_tests.sh"
      - "tests/run_code_style.sh"
      - "examples/**.py"
      - "requirements-dev.txt"
      - ".github/workflows/gpu-tests.yml"
  workflow_dispatch:

concurrency:
  # <workflow_name>-<branch_name>-<true || commit_sha (if branch is protected)>
  group: gpu-tests-${{ github.ref_name }}-${{ !(github.ref_protected) || github.sha }}
  cancel-in-progress: true

# Cherry-picked from https://github.com/pytorch/test-infra/blob/main/.github/workflows/linux_job.yml

jobs:
  gpu-tests:    
    strategy:
      matrix:
        pytorch-channel: [pytorch, pytorch-nightly]
      fail-fast: false
    env:
      DOCKER_IMAGE: "pytorch/conda-builder:cuda11.7"
      REPOSITORY: ${{ github.repository }}
      PR_NUMBER: ${{ github.event.pull_request.number }}
    runs-on: linux.8xlarge.nvidia.gpu
    timeout-minutes: 45

    steps:
      #######
      # Cherry-picked from https://github.com/pytorch/test-infra/blob/main/.github/workflows/linux_job.yml
      - name: Clean workspace
        run: |
          echo "::group::Cleanup debug output"
          sudo rm -rfv "${GITHUB_WORKSPACE}"
          mkdir -p "${GITHUB_WORKSPACE}"
          echo "::endgroup::"

      - name: Checkout repository (pytorch/test-infra)
        uses: actions/checkout@v3
        with:
          # Support the use case where we need to checkout someone's fork
          repository: pytorch/test-infra
          path: test-infra

      - name: Setup Linux
        uses: ./test-infra/.github/actions/setup-linux

      - name: Pull docker image
        uses: ./test-infra/.github/actions/pull-docker-image
        with:
          docker-image: ${{ env.DOCKER_IMAGE }}

      - name: Checkout repository (${{ github.repository }})
        uses: actions/checkout@v3
        with:
          # Support the use case where we need to checkout someone's fork
          repository: ${{ github.repository }}
          ref: ${{ github.ref }}
          path: ${{ github.repository }}
          fetch-depth: 1
      # End of cherry-picked from https://github.com/pytorch/test-infra/blob/main/.github/workflows/linux_job.yml      
      #######

      - uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Install PyTorch
        # https://pytorch.org/get-started/locally/
        if: ${{ matrix.pytorch-channel == 'pytorch' }}
        run: |
          pip install --upgrade torch torchvision --extra-index-url https://download.pytorch.org/whl/cu117
          nvidia-smi
          python -c "import torch; print(torch.__version__, ', CUDA is available: ', torch.cuda.is_available()); exit(not torch.cuda.is_available())"
          pip list

      - name: Install PyTorch (nightly)
        # https://pytorch.org/get-started/locally/
        if: ${{ matrix.pytorch-channel == 'pytorch-nightly' }}
        run: |
          pip install --upgrade --pre torch torchvision --extra-index-url https://download.pytorch.org/whl/nightly/cu117
          nvidia-smi
          python -c "import torch; print(torch.__version__, ', CUDA is available: ', torch.cuda.is_available()); exit(not torch.cuda.is_available())"
          pip list

      - name: Install dependencies
        run: |
          pip install -r requirements-dev.txt
          pip install -e .

      - name: Run 1 Node 2 GPUs Unit Tests
        run: |
          bash tests/run_gpu_tests.sh 2

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: gpu-2
          fail_ci_if_error: false

      - name: Install additional example dependencies
        run: pip install fire

      - name: Check training on cifar10, run without backend
        run: |
          export example_path="examples/contrib/cifar10"
          # initial run
          export stop_cmd="--stop_iteration=500"
          CI=1 python ${example_path}/main.py run --checkpoint_every=200 ${stop_cmd}
          # resume
          export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-None-1_stop-on-500/training_checkpoint_400.pt"
          CI=1 python ${example_path}/main.py run --checkpoint_every=200 --num_epochs=7 ${resume_opt}

      - name: Check training on cifar10, run with NCCL backend using torchrun
        run: |
          export example_path="examples/contrib/cifar10"
          # initial run
          export stop_cmd="--stop_iteration=500"
          CI=1 torchrun --nproc_per_node=2 ${example_path}/main.py run --backend=nccl --checkpoint_every=200 ${stop_cmd}
          # resume
          export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-nccl-2_stop-on-500/training_checkpoint_400.pt"
          CI=1 torchrun --nproc_per_node=2 ${example_path}/main.py run --backend=nccl --checkpoint_every=200 --num_epochs=7 ${resume_opt}

      - name: Check training on cifar10, run with NCCL backend using spawn
        run: |
          export example_path="examples/contrib/cifar10"
          # initial run
          export stop_cmd="--stop_iteration=500"
          CI=1 python -u ${example_path}/main.py run --backend=nccl --nproc_per_node=2 --checkpoint_every=200 ${stop_cmd}
          # resume
          export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-nccl-2_stop-on-500/training_checkpoint_400.pt"
          CI=1 python -u ${example_path}/main.py run --backend=nccl --nproc_per_node=2 --checkpoint_every=200 --num_epochs=7 ${resume_opt}

      #######
      # Cherry-picked from https://github.com/pytorch/test-infra/blob/main/.github/workflows/linux_job.yml

      - name: Teardown Linux
        if: ${{ always() }}
        uses: ./test-infra/.github/actions/teardown-linux

      # End of cherry-picked from https://github.com/pytorch/test-infra/blob/main/.github/workflows/linux_job.yml      
      #######
